[project]
name = "backend"
version = "0.1.0"
description = "Backend API server for chatbot application"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "fastapi>=0.116.1",
    "httpx>=0.27.0",
    "langchain>=0.3.27",
    "langchain-milvus>=0.2.1",
    "langchain-mcp-adapters>=0.1.0",
    "langchain-nvidia-ai-endpoints>=0.3.13",
    "langchain-openai>=0.3.28",
    "langchain-text-splitters>=0.3.9",
    "langchain-unstructured>=0.1.6",
    "langgraph>=0.6.0",
    "mcp>=0.1.0",
    "pydantic>=2.11.7",
    "pypdf2>=3.0.1",
    "python-dotenv>=1.1.1",
    "python-multipart>=0.0.20",
    "asyncpg>=0.29.0",
    "requests>=2.28.0",
    "unstructured[pdf]>=0.18.11",
    "uvicorn>=0.35.0",
    "websockets>=15.0.1",
    # Rate limiting
    "slowapi>=0.1.9",
    # JWT authentication
    "python-jose[cryptography]>=3.3.0",
    # LlamaIndex dependencies for enhanced RAG
    "llama-index-core>=0.13.0",
    "llama-index-vector-stores-milvus>=0.9.4",
    "llama-index-embeddings-openai>=0.3.0",
    "llama-index-embeddings-openai-like>=0.2.0",
    "llama-index-readers-file>=0.3.0",
    # BM25 for hybrid search
    "rank-bm25>=0.2.2",
    # Redis for query cache
    "redis>=5.0.0",
    # Langfuse for LLM observability and token tracking
    # NOTE: Must use v2 (>=2.0.0,<3.0.0) - v3 has incompatible API
    "langfuse>=2.0.0,<3.0.0",
    "tiktoken>=0.9.0",
]
