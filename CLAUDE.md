# NVIDIA Multi-Agent Chatbot — Claude Code Instructions

## Project Overview
- RAG-based multi-agent chatbot on DGX Spark (Grace Blackwell, 128GB unified memory)
- Backend: `assets/backend/` — Python 3.12, FastAPI + LangGraph
- Frontend: `assets/frontend/` — Vite 7 + React 19 + TypeScript, shadcn/ui
- Infra: Docker Compose (`assets/docker-compose.yml`, `assets/docker-compose-models.yml`)

## Local Models (NIM on DGX Spark)

| Model | Service Host | Purpose | Quantization | VRAM |
|-------|-------------|---------|-------------|------|
| GPT-OSS-120B | `gpt-oss-120b:8000` | Main LLM | MXFP4 | ~63.5GB |
| Deepseek-Coder 6.7B | `deepseek-coder:8000` | Code generation | Q8 | ~9.5GB |
| Qwen3-Embedding-4B | `qwen3-embedding:8000` | Embeddings | Q8 | ~5.39GB |

Total VRAM: ~100GB / 128GB available

## Architecture Rules

### R1. Single Responsibility
- `main.py`: App factory + lifespan + router mount ONLY (230 lines)
- `agent/`: LangGraph ChatAgent package (6 files, ~786 lines)
- `routers/`: HTTP handling, delegate to services (4 files, ~962 lines)
- `services/`: Business logic (7 files, ~1502 lines)
- `infrastructure/`: External API wrappers ONLY (5 files, ~547 lines)
- `rag/`: RAG pipeline modules (6 files, ~978 lines)
- `dependencies/`: FastAPI Depends() factories (2 files, ~72 lines)

### R2. No Direct Infrastructure in Routers
```
FORBIDDEN: from pymilvus import connections
REQUIRED:  from dependencies.providers import get_milvus_client
```

### R3. API Conventions
- Prefix: `/api/v1/` for all endpoints (except `/health` at root)
- Response: `{"data": {...}}` or `{"error": {"code": "...", "message": "...", "details": {...}}}`
- Use `errors.py` helpers — never raw `HTTPException`

### R4. Dependency Injection
- Use FastAPI `Depends()` for all dependencies
- No global variables (`agent`, `postgres_storage`, `vector_store`)
- Use `@lru_cache` for singleton patterns

### R5. Import Order (PEP 8)
1. Standard library
2. Third-party
3. Local application

## Commands

```bash
# Backend (must activate venv first)
cd assets/backend && source .venv/bin/activate
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Run all tests (tests live in assets/tests/, NOT assets/backend/tests/)
cd assets/backend && pytest ../tests/ -v

# Run single test file
cd assets/backend && pytest ../tests/test_api.py -v
cd assets/backend && pytest ../tests/test_api.py::test_health -v

# Frontend
cd assets/frontend && pnpm dev   # port 3000

# Health check
curl http://localhost:8000/health

# Package management (use uv, not pip)
cd assets/backend && uv add <package>
cd assets/backend && uv sync
```

## Critical Environment Variables

| Variable | Default | Purpose |
|----------|---------|---------|
| `MODELS` | (required) | Comma-separated model names, e.g. `gpt-oss-120b,deepseek-coder` |
| `LLM_API_TYPE` | `local` | `local` for NIM or `openai` for external API |
| `LLM_BASE_URL` | `http://gpt-oss-120b:8000/v1` | LLM endpoint |
| `LLM_API_KEY` | `api_key` | API key (local models don't need real key) |
| `SUPABASE_JWT_SECRET` | (unset) | If set, enables JWT auth |
| `POSTGRES_HOST` | `postgres` | PostgreSQL host |

## Key Files
- API docs: `http://localhost:8000/docs` (auto-generated by FastAPI)

## Dependency Version Constraints
- **Langfuse MUST be v2** (`>=2.0.0,<3.0.0`) — v3 has incompatible API
- Python: 3.12 (not 3.10/3.11)

@assets/backend/CLAUDE.md
